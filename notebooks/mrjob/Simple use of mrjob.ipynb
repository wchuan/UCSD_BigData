{
 "metadata": {
  "name": "",
  "signature": "sha256:065c1d2dc54c85dc893d8eefbdaca994bf5eb26bee5105bc62c57fcca5810fe9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##mrjob##\n",
      "\n",
      "__mrjob__ is a software package developed by the restaurant recommendation company _Yelp_. \n",
      "It's goal is to simplify the deployment of map-reduce jobs based on streaming and python onto different \n",
      "frameworks such as Hadoop on a private cluster or hadoop on AWS (called EMR).\n",
      "\n",
      "* You can read more about mrjob here: https://pythonhosted.org/mrjob/index.html  \n",
      "* and you can clone it from github here: https://github.com/yelp/mrjob\n",
      "\n",
      "In this notebook we run a simple word-count example, add to it some logging commands, and look at two modes of running the job."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "root_dir = '/home/ubuntu/packages/mrjob'\n",
      "examples_dir=root_dir+'/examples/'\n",
      "!ls -l $examples_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 92\r\n",
        "drwxrwxr-x 2 ubuntu ubuntu  4096 May  1 14:34 bash_wrap\r\n",
        "drwxrwxr-x 2 ubuntu ubuntu  4096 May  1 14:34 contrib\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu     0 May  1 14:34 __init__.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  3176 May  1 14:34 mr_cmd.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  1198 May  1 14:34 mr_grep.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  2125 May  1 14:34 mr_jar_step_example.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  4108 May  1 14:34 mr_log_sampler.py\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu  1972 May  1 14:34 mr_most_used_word.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  3400 May  1 14:34 mr_next_word_stats.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  3501 May  1 14:34 mr_page_rank.py\r\n",
        "drwxrwxr-x 2 ubuntu ubuntu  4096 May  1 14:34 mr_postfix_bounce\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu 21954 May  1 14:34 mr_text_classifier.py\r\n",
        "drwxrwxr-x 3 ubuntu ubuntu  4096 May  1 14:34 mr_travelling_salesman\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  1552 May  1 14:34 mr_wc.py\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu  1977 May  1 14:34 mr_wc.rb\r\n",
        "-rwxrwxr-x 1 ubuntu ubuntu  1065 May  1 14:34 mr_word_freq_count.py\r\n",
        "-rw-rw-r-- 1 ubuntu ubuntu  4887 May  1 14:34 py3k_word_freq_count.py\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filename=examples_dir+'mr_word_freq_count.py'\n",
      "print filename\n",
      "!ls $filaname\n",
      "# load example code from mr jobs as a starting point\n",
      "%load  $filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/ubuntu/packages/mrjob/examples/mr_word_freq_count.py\n",
        "counts\tmr_word_freq_count.py  Simple use of mrjob.ipynb\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%writefile mr_word_freq_count.py\n",
      "#!/usr/bin/python\n",
      "# Copyright 2009-2010 Yelp\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "# http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\"\"\"The classic MapReduce job: count the frequency of words.\n",
      "\"\"\"\n",
      "from mrjob.job import MRJob\n",
      "import re\n",
      "from sys import stderr\n",
      "\n",
      "WORD_RE = re.compile(r\"[\\w']+\")\n",
      "\n",
      "#logfile=open('log','w')\n",
      "logfile=stderr\n",
      "\n",
      "class MRWordFreqCount(MRJob):\n",
      "\n",
      "    def mapper(self, _, line):\n",
      "        for word in WORD_RE.findall(line):\n",
      "            #logfile.write('mapper '+word.lower()+'\\n')\n",
      "            yield (word.lower(), 1)\n",
      "\n",
      "    def combiner(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('combiner '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "    def reducer(self, word, counts):\n",
      "        yield (word, sum(counts))\n",
      "        #l_counts=[c for c in counts]  # extract list from iterator\n",
      "        #S=sum(l_counts)\n",
      "        #logfile.write('reducer '+word+' ['+','.join([str(c) for c in l_counts])+']='+str(S)+'\\n')\n",
      "        #yield (word, S)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    MRWordFreqCount.run()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting mr_word_freq_count.py\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py $root_dir/README.rst > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no configs found; falling back on auto-configuration\r\n",
        "no configs found; falling back on auto-configuration\r\n",
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/step-0-mapper_part-00000\r\n",
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/step-0-mapper_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/step-0-reducer_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/output/part-00000\r\n",
        "Streaming final output from /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140501.173338.058836\r\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat log"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cat: log: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\"'__main__'\"\t1\r\n",
        "\"04\"\t1\r\n",
        "\"05\"\t1\r\n",
        "\"08\"\t1\r\n",
        "\"1\"\t1\r\n",
        "\"2\"\t2\r\n",
        "\"2009\"\t1\r\n",
        "\"2010\"\t1\r\n",
        "\"2011\"\t4\r\n",
        "\"2012\"\t1\r\n",
        "\"4\"\t1\r\n",
        "\"4898987\"\t1\r\n",
        "\"5\"\t1\r\n",
        "\"_\"\t18\r\n",
        "\"__name__\"\t1\r\n",
        "\"a\"\t3\r\n",
        "\"access\"\t1\r\n",
        "\"accordingly\"\t1\r\n",
        "\"account\"\t3\r\n",
        "\"advanced\"\t2\r\n",
        "\"aimotion\"\t1\r\n",
        "\"allows\"\t1\r\n",
        "\"also\"\t1\r\n",
        "\"amazon\"\t6\r\n",
        "\"amazon's\"\t1\r\n",
        "\"an\"\t2\r\n",
        "\"analysis\"\t2\r\n",
        "\"and\"\t12\r\n",
        "\"apache\"\t1\r\n",
        "\"automatically\"\t1\r\n",
        "\"aws\"\t5\r\n",
        "\"aws_access_key_id\"\t2\r\n",
        "\"aws_secret_access_key\"\t2\r\n",
        "\"basics\"\t1\r\n",
        "\"basis\"\t1\r\n",
        "\"blind\"\t3\r\n",
        "\"blip\"\t1\r\n",
        "\"blogspot\"\t1\r\n",
        "\"buy\"\t1\r\n",
        "\"by\"\t1\r\n",
        "\"ci\"\t2\r\n",
        "\"class\"\t1\r\n",
        "\"classic\"\t1\r\n",
        "\"click\"\t1\r\n",
        "\"cluster\"\t5\r\n",
        "\"code\"\t4\r\n",
        "\"com\"\t10\r\n",
        "\"combiner\"\t1\r\n",
        "\"compile\"\t1\r\n",
        "\"computing\"\t1\r\n",
        "\"conf\"\t6\r\n",
        "\"config\"\t1\r\n",
        "\"configs\"\t1\r\n",
        "\"configuration\"\t1\r\n",
        "\"contents\"\t1\r\n",
        "\"count\"\t1\r\n",
        "\"counts\"\t7\r\n",
        "\"create\"\t1\r\n",
        "\"credentials\"\t1\r\n",
        "\"def\"\t3\r\n",
        "\"development\"\t1\r\n",
        "\"discussion\"\t1\r\n",
        "\"distributed\"\t1\r\n",
        "\"docs\"\t2\r\n",
        "\"documentation\"\t5\r\n",
        "\"duplicate\"\t1\r\n",
        "\"e\"\t1\r\n",
        "\"easily\"\t1\r\n",
        "\"elastic\"\t5\r\n",
        "\"elasticmapreduce\"\t2\r\n",
        "\"emr\"\t9\r\n",
        "\"en\"\t1\r\n",
        "\"environment\"\t3\r\n",
        "\"error\"\t1\r\n",
        "\"etc\"\t1\r\n",
        "\"everyone\"\t1\r\n",
        "\"example\"\t1\r\n",
        "\"examples\"\t4\r\n",
        "\"features\"\t2\r\n",
        "\"feeds\"\t1\r\n",
        "\"file\"\t2\r\n",
        "\"findall\"\t1\r\n",
        "\"for\"\t8\r\n",
        "\"frequency\"\t1\r\n",
        "\"from\"\t5\r\n",
        "\"fully\"\t1\r\n",
        "\"g\"\t1\r\n",
        "\"get\"\t1\r\n",
        "\"github\"\t3\r\n",
        "\"google\"\t1\r\n",
        "\"graph\"\t2\r\n",
        "\"greg\"\t2\r\n",
        "\"group\"\t2\r\n",
        "\"groups\"\t1\r\n",
        "\"guides\"\t1\r\n",
        "\"hadoop\"\t11\r\n",
        "\"hadoop_home\"\t1\r\n",
        "\"handled\"\t1\r\n",
        "\"helps\"\t1\r\n",
        "\"hourly\"\t1\r\n",
        "\"html\"\t3\r\n",
        "\"http\"\t16\r\n",
        "\"https\"\t3\r\n",
        "\"if\"\t1\r\n",
        "\"image\"\t2\r\n",
        "\"import\"\t2\r\n",
        "\"important\"\t1\r\n",
        "\"in\"\t5\r\n",
        "\"information\"\t2\r\n",
        "\"inside\"\t1\r\n",
        "\"install\"\t4\r\n",
        "\"installation\"\t1\r\n",
        "\"interpret\"\t1\r\n",
        "\"into\"\t1\r\n",
        "\"introduction\"\t2\r\n",
        "\"is\"\t2\r\n",
        "\"it\"\t3\r\n",
        "\"its\"\t1\r\n",
        "\"job\"\t4\r\n",
        "\"job's\"\t1\r\n",
        "\"jobs\"\t3\r\n",
        "\"keys\"\t1\r\n",
        "\"killion\"\t1\r\n",
        "\"latest\"\t1\r\n",
        "\"line\"\t2\r\n",
        "\"links\"\t1\r\n",
        "\"live\"\t1\r\n",
        "\"locally\"\t2\r\n",
        "\"logo\"\t1\r\n",
        "\"logo_medium\"\t1\r\n",
        "\"logos\"\t1\r\n",
        "\"logs\"\t1\r\n",
        "\"looks\"\t1\r\n",
        "\"lower\"\t1\r\n",
        "\"mailto\"\t1\r\n",
        "\"make\"\t3\r\n",
        "\"map\"\t2\r\n",
        "\"mapper\"\t1\r\n",
        "\"mapreduce\"\t8\r\n",
        "\"marcelcaraciolo\"\t1\r\n",
        "\"master\"\t1\r\n",
        "\"minimal\"\t1\r\n",
        "\"more\"\t3\r\n",
        "\"mr_word_freq_count\"\t3\r\n",
        "\"mrjob\"\t31\r\n",
        "\"mrjob_conf\"\t1\r\n",
        "\"mrwordfreqcount\"\t2\r\n",
        "\"multi\"\t1\r\n",
        "\"need\"\t1\r\n",
        "\"net\"\t3\r\n",
        "\"next\"\t1\r\n",
        "\"of\"\t2\r\n",
        "\"on\"\t10\r\n",
        "\"one\"\t1\r\n",
        "\"only\"\t1\r\n",
        "\"or\"\t1\r\n",
        "\"org\"\t7\r\n",
        "\"other\"\t3\r\n",
        "\"out\"\t1\r\n",
        "\"overview\"\t1\r\n",
        "\"own\"\t2\r\n",
        "\"package\"\t1\r\n",
        "\"packages\"\t4\r\n",
        "\"page\"\t1\r\n",
        "\"pip\"\t1\r\n",
        "\"png\"\t2\r\n",
        "\"postneo\"\t1\r\n",
        "\"production\"\t1\r\n",
        "\"project\"\t1\r\n",
        "\"put\"\t1\r\n",
        "\"py\"\t4\r\n",
        "\"pycon\"\t3\r\n",
        "\"pypi\"\t1\r\n",
        "\"pypy\"\t2\r\n",
        "\"python\"\t10\r\n",
        "\"pythonpath\"\t1\r\n",
        "\"r\"\t3\r\n",
        "\"raw\"\t1\r\n",
        "\"re\"\t2\r\n",
        "\"readme\"\t3\r\n",
        "\"readthedocs\"\t1\r\n",
        "\"recommendations\"\t2\r\n",
        "\"recsys\"\t1\r\n",
        "\"reduce\"\t2\r\n",
        "\"reducer\"\t1\r\n",
        "\"reference\"\t1\r\n",
        "\"regions\"\t1\r\n",
        "\"rst\"\t3\r\n",
        "\"run\"\t8\r\n",
        "\"scripts\"\t1\r\n",
        "\"secret\"\t1\r\n",
        "\"security\"\t1\r\n",
        "\"see\"\t1\r\n",
        "\"self\"\t3\r\n",
        "\"service\"\t1\r\n",
        "\"services\"\t1\r\n",
        "\"set\"\t5\r\n",
        "\"setting\"\t1\r\n",
        "\"setup\"\t4\r\n",
        "\"sign\"\t1\r\n",
        "\"simple\"\t1\r\n",
        "\"simplejson\"\t1\r\n",
        "\"social\"\t2\r\n",
        "\"some\"\t1\r\n",
        "\"source\"\t5\r\n",
        "\"ssh\"\t1\r\n",
        "\"stable\"\t1\r\n",
        "\"stable1\"\t1\r\n",
        "\"step\"\t2\r\n",
        "\"streaming\"\t3\r\n",
        "\"sum\"\t2\r\n",
        "\"supports\"\t1\r\n",
        "\"sure\"\t1\r\n",
        "\"tarballs\"\t1\r\n",
        "\"target\"\t1\r\n",
        "\"testing\"\t1\r\n",
        "\"thanks\"\t1\r\n",
        "\"that\"\t1\r\n",
        "\"the\"\t7\r\n",
        "\"this\"\t1\r\n",
        "\"time\"\t1\r\n",
        "\"to\"\t9\r\n",
        "\"tracker\"\t1\r\n",
        "\"transparently\"\t1\r\n",
        "\"travis\"\t2\r\n",
        "\"tree\"\t2\r\n",
        "\"try\"\t1\r\n",
        "\"tunnel\"\t1\r\n",
        "\"tv\"\t1\r\n",
        "\"tz\"\t1\r\n",
        "\"up\"\t3\r\n",
        "\"upload\"\t2\r\n",
        "\"us\"\t1\r\n",
        "\"use\"\t1\r\n",
        "\"using\"\t2\r\n",
        "\"v0\"\t1\r\n",
        "\"variables\"\t2\r\n",
        "\"version\"\t2\r\n",
        "\"videos\"\t1\r\n",
        "\"w'\"\t1\r\n",
        "\"web\"\t1\r\n",
        "\"which\"\t1\r\n",
        "\"with\"\t3\r\n",
        "\"word\"\t6\r\n",
        "\"word_re\"\t2\r\n",
        "\"words\"\t1\r\n",
        "\"works\"\t4\r\n",
        "\"write\"\t2\r\n",
        "\"www\"\t1\r\n",
        "\"yelp\"\t4\r\n",
        "\"yield\"\t3\r\n",
        "\"you\"\t2\r\n",
        "\"you'll\"\t1\r\n",
        "\"your\"\t10\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What is the meaning of \"yield\" ?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The keyword __yield__ is somewhat similar to __return__ however, while __return__ terminates the function and returns the result, \n",
      "__yield__, the first time it is encountered, return an object called a __generator__, without executing the function even once. On subsequent calls, the function is executed until one or more __yield__ commands are encountered, these values are returned, and the function halts (but does not terminate) until it is called again.\n",
      "\n",
      "Here is a simple example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def myrange(start,stop,step):\n",
      "    value=start\n",
      "    while value<=stop:\n",
      "        yield value\n",
      "        value += step\n",
      "print [x for x in myrange(1.0,3.0,0.3)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1.0, 1.3, 1.6, 1.9000000000000001, 2.2, 2.5, 2.8]\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print myrange(1.0,3.0,0.3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<generator object myrange at 0x217e870>\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gen1=myrange(1.0,3.0,0.3)\n",
      "gen2=myrange(2.0,5.0,0.7)\n",
      "print 'gen1:',[x for x in gen1]\n",
      "print 'gen1:',[x for x in gen1]  # after the generator terminated, it does not yield any more values.\n",
      "print 'gen2:',[x for x in gen2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gen1: [1.0, 1.3, 1.6, 1.9000000000000001, 2.2, 2.5, 2.8]\n",
        "gen1: []\n",
        "gen2: [2.0, 2.7, 3.4000000000000004, 4.1000000000000005, 4.800000000000001]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A generator is similar to an array or a list, all of those are __iterable__ objects. However, while list store all of the values in memory and can be read in any order, generators create the values on the fly and can only traversed __once__ and __in order__\n",
      "\n",
      "It is the fact that values are generated on the fly and then discarded which makes generators attractive when processing large amounts of data - only a small amount of intermedite results, the outputs of the mapper which are inputs to the reducer, need to be stored in memory. How much depends on the communication speed between mappers and reducers.\n",
      "\n",
      "It is instructive to see how generators can be cascaded by passing a generator as a parameter to another generator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mycumul(values):   # values can be a list or a generator.\n",
      "    s=0\n",
      "    for value in values:\n",
      "        s+=value\n",
      "        yield s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here we pass a generator as an input to another generator.\n",
      "gen3=mycumul(myrange(1.0,3.0,0.3))   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'gen3:',[x for x in gen3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gen3: [1.0, 2.3, 3.9, 5.8, 8.0, 10.5, 13.3]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Different modes of running a mrjob map-reduce job ##\n",
      "\n",
      "Once the mapper, combiner and reducer have been written and tested, you can run the job on different types of infrastructure:\n",
      "\n",
      "1. __inline__ run the job as a single process on the local machine.\n",
      "1. __local__ run the job on the local machine, but using multiple processes to simulate parallel processing.\n",
      "1. __hadoop__ run the job on a hadoop cluster (such as the one we have in SDSC)\n",
      "1. __EMR__ (Elastic Map Reduce) run the job on a hadoop cluster running on the amazon cloud.\n",
      "\n",
      "Below we run the same process we ran at the top using __local__ instead of the default __inline__. Observe that in this case the reducers have some non-trivial work to do even when combiners are used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python mr_word_freq_count.py --runner=local $root_dir/README.rst > counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no configs found; falling back on auto-configuration\r\n",
        "no configs found; falling back on auto-configuration\r\n",
        "creating tmp directory /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/input_part-00000 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00000\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --mapper /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/input_part-00001 | sort | /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --combiner > /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper-sorted\r\n",
        "> sort /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00000 /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-mapper_part-00001\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00000\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/input_part-00000 > /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00000\r\n",
        "writing to /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00001\r\n",
        "> /home/ubuntu/anaconda/bin/python mr_word_freq_count.py --step-num=0 --reducer /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/input_part-00001 > /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00001\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counters from step 1:\r\n",
        "  (no counters found)\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00000 -> /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/output/part-00000\r\n",
        "Moving /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/step-0-reducer_part-00001 -> /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/output/part-00001\r\n",
        "Streaming final output from /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400/output\r\n",
        "removing tmp directory /tmp/mr_word_freq_count.ubuntu.20140501.173505.075400\r\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls mrjob/examples/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "__init__.py             mr_jar_step_example.py  \u001b[34mmr_postfix_bounce\u001b[m\u001b[m       \u001b[31mmr_word_freq_count.py\u001b[m\u001b[m\r\n",
        "\u001b[34mbash_wrap\u001b[m\u001b[m               mr_log_sampler.py       mr_text_classifier.py   py3k_word_freq_count.py\r\n",
        "\u001b[34mcontrib\u001b[m\u001b[m                 \u001b[31mmr_most_used_word.py\u001b[m\u001b[m    \u001b[34mmr_travelling_salesman\u001b[m\u001b[m\r\n",
        "mr_cmd.py               mr_next_word_stats.py   mr_wc.py\r\n",
        "mr_grep.py              mr_page_rank.py         \u001b[31mmr_wc.rb\u001b[m\u001b[m\r\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load $root_dir/examples/mr_travelling_salesman/README.rst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### HW ###\n",
      "1) Look around in the examples directory\n",
      "2) Write a map-reduce job that computes the PCA of a large set of vectors (use as input the max_temp profiles in \n",
      "   /home/ubuntu/data/weather/SAMPLE_TMAX.csv)\n",
      "\n",
      "**Hint:** One map-reduce job is enough. You might think that you first need to compute the means $\\mu_i=E(X_i)$ and then, in a second path, compute\n",
      "$$cov(X_i,X_j) = E((X_i-\\mu_i)(X_j-\\mu_j))$$\n",
      "However, recall the formula \n",
      "$$ var(X) \\doteq E((X-\\mu)^2) = E(X^2) - E(X)^2 $$\n",
      "This formula can be generalized to the $cov$ matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc /home/ubuntu/data/weather/SAMPLE_TMAX.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "   20000    20000 26114979 /home/ubuntu/data/weather/SAMPLE_TMAX.csv\r\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}